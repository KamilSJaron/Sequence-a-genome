---
  output: pdf_document
---

We expected, that you will use this document as manual of tools for your analysis, so we have kept here the R part from the last week. We recommend you to add the rest of downstream analysis on genes to the same R script, you have created last week. Do not hesitate write comments in your code.

***

#RNA-seq downstream analysis (ex3)

## 1. Reading annotation.

First of all, we need to load information about relation transcripts to genes and lengths of genes from annotation file.

1. Use `import.gff` function form `rtracklayer` package to load annotation and convert it to `data.frame`

```{r, message=FALSE, warning=FALSE}
### To install the rtracklayer from Bioconductor
# source("https://bioconductor.org/biocLite.R")
# biocLite("rtracklayer")

library(rtracklayer)

# imports our gtf file (don't provide any other .txt files) 
gtf <- import.gff("../genome/Pseudomonas_protegens_S5_genome.gtf")
gtf <- as.data.frame(gtf)
head(gtf)
```

\footnotesize
Once, the `.gtf` file is loaded, the variable `gtf` will carry an non-standard R object. We can convert it to a `data.frame` object, which we are more familiar with.
\normalsize

We are going to need a dictionary of transcripts and gene IDs to quantify expression of genes.

2. Create a `data.frame` which will be used as dictionary between transcripts and genes. 

```{r}
# associate transcripts to your genes
tx2genes <- data.frame(tx_name = gtf$transcript_id, 
                    gene_id = gtf$gene_id, 
                    stringsAsFactors = FALSE)

head(tx2genes)
```

3. Check how many times are there genes with multiple transcripts.

```{r}
table(table(tx2genes$gene_id))
```

\footnotesize
\textbf{table of table}: `table` transforms a vector to table of counts from the vector. If you apply function `table` to vector `c('A','A','B','C','C','C','D','D')` it returns a vector `c(2,1,3,2)` with names `c('A','B','C','D')`. If you apply function `table` to the returned vector (the vector `c(2,1,3,2)`), it computes counts of counts - the output will be then `c(1,2,1)` with names `c(1,2,3)`. So we can see that in the original vector there was one letter represented one time (`'B'`), two letters represented twice (`'A'`, `'D'`) and one letter represented three times (`'C'`)
\normalsize

We are also going to need to know lengths of genes to compute RPKM.

4. Compute lengths of all genes as the length of the longest transcript. 

```{r}
# check the function aggregate
geneLength <- aggregate(gtf$width, list(gtf$gene_id), max)
colnames(geneLength) <- c("gene_name", "length")
```

\footnotesize
\textbf{aggregate}: Function `aggregate` can apply a function (`max` in our case) to subsets of data (`gtf$width`) given by of type `vector` or `list` (`list(gtf$gene_id)`).
\normalsize

***

## 2. Load data

\footnotesize
The starting point for an RNA-Seq experiment is a set of N RNA samples, typically associated with a variety of treatment conditions. Each sample is sequenced, short reads are mapped to the appropriate genome, and the number of reads mapped to each genomic feature of interest is recorded. 

The set of gene-wise counts for sample j makes up the expression profile or library for that sample. The expected size of each count is the product of the library size and the relative abundance of that gene in that sample. As input for data analysis, we expect count data in the form of a matrix of integer values. The matrix in the g-th row and the j-th column of the table tells how many reads have been mapped to gene g in sample j.
\normalsize

1. Download abundances

Windows users have to use WinSCP, but OS X and Linux users can use command `rsync` for downloading shared directories. The advantage of `rsync` is that it does not simply copy, but rather synchronise. So if you folder already contains some files, they won't be downloaded again. If you are feeling uncomfortable with this feature, you can use `scp` instead.

```bash
rsync -r <username>@prd.vital-it.ch:/scratch/cluster/monthly/mls_2015/SAGE/abundances .
```

2. Load all needed packages, save all filenames of abundances to variable `files` using function `dir`. Check in the manual what the function does.

```{r, message=FALSE, warning=FALSE}
## Load the packages


#### To install package edgeR, use Bioconductor
# source("http://bioconductor.org/biocLite.R")
# biocLite(c("edgeR", "ggplot2"))

### To install other packages
# install.packages(c("readr", "reshape2", "pheatmap"))


# call the packages
library(edgeR)
library(readr)
library(ggplot2)
library(pheatmap)
library(reshape2)


# provide the full path to your folder with abundances
path_to_abundances <- '../abundances/'
# this imports the .tsv files in your R environment 
files <- dir(path_to_abundances, pattern=".tsv$")
# paste the path to your files - make sure that you have the path in front the files
files <- paste0(path_to_abundances, files)
files
```

3. Load the function `tximport` from script `tximport.R`. You can download the script from \newline `/scratch/cluster/monthly/mls_2015/SAGE/scripts/tximport.R`. We will use this function to load transcript abundances

```{r, message=FALSE}
# load the script with tximport.
source('../scripts/tximport.R')
```

\footnotesize
\textbf{tximport}: is a package which is not released for the current version of R (R-2.x). If you will try to install package via bioconductor, you will probably fail, unless you have installed the non-yet-released version of R (beta R-3.3). Hopefully, the content of this package is quite simple. Therefore, we can load the content of the package load to R by just using `source()` on the source code of the package.
\normalsize

4. Import transcript abundances using function `tximport`. This function automatically recomputes transcript abundances to gene abundances using the list you have created earlier. Rename names of columns to condition and biological replicate...

```{r, message=FALSE}
txi <- tximport(files, type = "kallisto", tx2gene = tx2genes, reader = read_tsv)
names(txi)

# reading names of conditions from filenames
colnames(txi$counts) <- paste0(rep(c('LM','SA','WL','WR'), each = 4), rep(1:4,4)) 

head(txi$counts) # this goes further to stat. analysis of EdgeR
```

***

## 3. Data transformation

1. Select data you will work on today.

```{r}
rawcounts <- txi$counts[,grep("^WL|WR", colnames(txi$counts))]
head(rawcounts)
```

2. Plot a histogram on one sample from raw counts data by using `hist` function. The plot should look similar to this:

```{r, echo = FALSE}
rawcounts.ggplot <- as.data.frame(txi$counts[,grep("^WL|WR", colnames(txi$counts))])
ggplot(rawcounts.ggplot, aes(x = WL1)) + geom_histogram(fill = "#525252", binwidth = 2000) + ggtitle("Histogram on Raw Counts for WL 1 sample")
```

3. Transform counts to log scale.

```{r}
pseudoCount <- log2(rawcounts + 1)
```

Do you have an idea, why there is a +1? What would happened if it was not there?

\footnotesize
For data exploration and visualization, it is useful to work with transformed versions of the count data. As the count values distribution is highly skewed, the log2 transformation helps to approximately normalize the distributions.

Log base 2 is typically used as it facilitates the conversion back to the original scale: a difference of 1 on the log base 2 scale corresponds to a fold change of 2 on the original count scale. Since count values for a gene can be zero in some conditions (and non-zero in others), we advocates the use of pseudocounts, i.e. transformations of the form

$Y = log_2(K+1)$; more generally $Y = log_2(K + k_0)$, where $K$ represents the count values and $k_0$ is a positive constant.

Even more, common statistical methods for exploratory analysis of multidimensional data, especially methods for clustering and ordination (e. g., principal-component analysis and the like), work best for (at least approximately) homoscedastic data; this means that all the observed data (i.e., here, the expression strength of a gene) share the same finite variance.
\normalsize

4. Plot a histogram of transformed counts by using `hist`. The plot should look similar to this:

```{r, echo = FALSE}
rawcounts.ggplot <- as.data.frame(txi$counts[,grep("^WL|WR", colnames(txi$counts))])
pseudoCount.ggplot <- log2(rawcounts.ggplot + 1)
ggplot(pseudoCount.ggplot, aes(x = WL1)) + ylab(expression(log[2](count + 1))) +
  geom_histogram(colour = "white", fill = "#525252", binwidth = 0.6) + ggtitle("Histogram on PseudoCounts for LM 1 sample")
```

***

## 4. Raw data filtering

For downstream analysis, it is usually worthwhile to remove genes that appear to be very lowly expressed in any of the experimental conditions. This is called filtering. 

There are a number of ways that filtering can be done. One way is to filter genes with a total read count smaller than a given threshold (Sultan et al. 2008) and filter genes with at least one zero count in each experimental condition (Bottomly et al. 2011); however, selecting an arbitrary threshold value to filter genes in this way does not account for the overall sequencing depth. 

To account differences in library size, a filter has also been proposed based on counts per million (CPM) (Robinson, McCarthy, and Smyth 2010), calculated as the raw counts divided by the library sizes and multiplied by one million. Genes with a CPM value less than a given cutoff (e.g. 1 or 100) in more samples (ignoring condition labels) than the size of the smallest group are subsequently filtered from the analysis. We filter out unexpressed genes, keeping genes that are expressed in at least 4 samples:

1. Calculate counts per million

```{r}
cpms <- cpm(rawcounts)
```

2. Trash weakly expressed genes - keep the features above the 1 count per million in at least one groups

```{r}
keep <- rowSums(cpms > 1) >= 4
countsFilter <- rawcounts[keep,]

dim(rawcounts)
dim(countsFilter)
```


```{r, message=FALSE, warning=FALSE}
pseudocountsFilter <- log2(countsFilter+1)
```

3. Plot histogram of pseudocounts for each sample of your conditions. The plot showed here is the stacked histograms, but you can make separate plots for each sample. Have a look at function `par` to plot many plots in one frame.

```{r, echo = FALSE}
pseudocountsFilter.ggplot <- as.data.frame(pseudocountsFilter)
dfFilter <- melt(pseudocountsFilter.ggplot)
dfFilter <- data.frame(dfFilter, Condition = substr(dfFilter$variable, 1, 2))
ggplot(dfFilter, aes(x = value, colour = variable, fill = variable)) +
  geom_histogram(binwidth = 0.6) + facet_wrap(~ Condition) +
  theme(legend.position = "top") + xlab("pseudocounts") + ggtitle("Filtered Pseudocounts distribution")
```

***

## 5. Data exploration and quality assessment

Data quality assessment (QA) and exploration are essential steps of any data analysis. These steps should typically be performed very early in the analysis of a new data set, preceding or in parallel to the normalization step and differential expression testing. 
Our purpose is the detection of differentially expressed genes, not of experimental errors. In particular, we want to identify and possibly remove samples whose experimental treatment suffered from an abnormality that renders the data points obtained from these particular samples detrimental to our purpose. 

The QA processes run on the raw data might reveal technical issues, but other biases might still be present in your data and the easiest way to control for those is visualisation. For example, one could compare replicates (in which case, biological replicates are best), by: 

- looking differences in count distribution between samples, 
-	plotting a scatterplot of replicates, 
-	sample clustering

In RNA-Seq data, however, variance grows with the mean, with larger variances for larger counts. For example, if one performs PCA directly on a matrix of “normalized” read counts, the result typically depends only on the few most strongly expressed genes because they show the largest absolute differences between samples. A simple strategy to avoid this is to take the logarithm of the “normalized” count values plus a small constant; however, now the genes with low counts tend to dominate the results because, due to the strong “Poisson” noise inherent to small count values, they show the strongest relative differences between samples.

In order to make counts approximately homoscedastic, the packages edgeR offers function `cpm` to transform the data.

\textcolor{red}{WARNING:} Note that these transformations are provided for applications other than differential testing. For differential testing to operate on raw counts and to use discrete distributions.


The boxplot provides an easy way to visualize the distribution of pseoudocounts in each sample. In the boxplot display, a box is formed with sides at the 25-th and 75-th quantiles of the distribution. A line within the box represent median. Whiskers, those lines out of the box, extend out from the box to minimal and maximal value respectively, but at most in the distance of the 1.5x interquartile range. Data points outside of this range are usually called outliers and plotted as individual points.

1. Make boxplots per samples using `boxplot`, `legend`.

```{r, echo  = FALSE}
## don't forget to use pseudocountsFilter
boxplot(pseudocountsFilter, ylab = "pseudocounts", col = rep(c("cyan3", "gold"), each = 4))
legend("topright", c("WL", "WR"), title = "Group", fill = c("cyan3", "gold"))
```

***

## 6. Clustering of the sample-to-sample distances

To explore the similarities and dissimilarities between samples, it is often instructive to look a clustering heatmap of sample-to-sample distance matrix. 
A heatmap is a two-dimensional, rectangular, coloured grid. It displays data that themselves come in the form of a square matrix:

- the colour of each rectangle is determined by the value of the corresponding entry in the matrix, 
-	the rows and columns of the matrix are rearranged independently according to some hierarchical clustering method (Euclidean distance is the most used one), so that similar rows and columns are placed next to each other, respectively

1. Plot a heatmap of Spearman correlations

```{r}
heatmap.plotting.replicates <- function(x, name){
	# calculate the spearman correlation on your samples
  spearman.tissue <- melt(cor(x, method = "spearman"))
	colnames(spearman.tissue)[3] <- "spear.corr"

	qp <- qplot(x=Var1, y=Var2, 
	            data=spearman.tissue, fill=spear.corr, 
	            geom="tile", xlab = "", ylab = "") + 
	  theme(panel.grid.major = element_blank(), 
	        panel.grid.minor = element_blank(), 
	        panel.background = element_blank(), 
	        axis.text.x = element_text(angle = 45, hjust = 1)) + 
	  labs(title = name)

	return(qp)
}

heatmap.plotting.replicates(pseudocountsFilter, "Heatmap WR-WL samples")
```

***

## 7. MDS of samples
The purpose of multidimensional scaling (MDS) is to provide a visual representation of the pattern of proximities (i.e., similarities or distances) among a set of objects. MDS takes a set of similarities and returns a set of points such that the distances between the points are approximately equal to the similarities. The similarities between each pair of samples (columns) is the root-mean-square deviation (Euclidean distance) for the top genes. Distances on the plot can be interpreted as leading log2-fold-change, meaning the typical (root-mean-square) log2-fold-change between the samples for the genes that distinguish those samples. The function plotMDS has an argument gene.selection which, set to "common", chooses as top genes those with the largest root-mean-square deviations between samples.

The plotMDS is a simple helper function from edgeR that performs the MDS and makes the plot.

1. Build a MDS plot of samples

```{r}
conditions <- c(rep("WL",4), rep("WR",4))
d <- DGEList(counts = countsFilter, group = conditions)
d <- calcNormFactors(d) # TMM is default - Estimate normalization factors

# inspect the relationships between your samples by mds plot
plotMDS(d, labels = colnames(cpms), 
        col = c("darkgreen","blue")[factor(conditions)], 
        main = "MDS plot on samples")
```

What do you see when you compare your conditions?

***

## 8. Differential expression analysis

Normalization is a process designed to identify and remove systematic technical differences between samples that occur in the data to ensure that technical bias has minimal impact on the results. The most common symptom of the need for normalization is differences in the total number of aligned reads.

*Depending on our data – TMM or upperquartile normalization method, explain here.

0. Normalize your data using TMM method.

```{r}
## normalization TMM
d <- estimateCommonDisp(d) 
d <- estimateTagwiseDisp(d)
```

Our focus: 

- Based on a count table, we want to detect differentially expressed genes between different conditions. How can we detect genes for which the counts of reads change between conditions more systematically than expected by chance (i.e. in the absence of a biologically interesting difference)?
- We would like to use statistical testing to decide whether, for a given gene, an observed difference in read counts is significant, that is, whether it is greater than what would be expected just due to natural random variation

**p-values**: It is a usual convention in biology to use a critical p-value of 0.05 (often called alpha, $\alpha$). This means that the probability of observing data as extreme as this if the null hypothesis is true is 0.05 (5% or 1 in 20); in other words, it indicates that the null hypothesis is unlikely to be true.

In hypothesis tests, researchers bounded the probability of making a type I error by $\alpha$, an “acceptable” risk of type I errors, conventionally set at 0.05. Problems arise, however, when researchers do not perform a single hypothesis test but many of them, in our case one for each gene. Because each test again has a probability of producing a type I error, by performing a large number of hypothesis tests a substantial number of false positives may accumulate. This problem is called the problem of multiple testing. The key goal of multiple testing methods is to control, or at least to quantify, the flood of type I errors that arise when many hypothesis tests are performed simultaneously
What does correcting for multiple testing mean? When people say “adjusting p-values for the number of hypothesis tests performed” what they mean is controlling a type I error measure.

Those that control the false discovery rate (FDR), give by FDR = E(Q).

The FDR looks at the expected proportion of false positives among all of the genes initially identified as being differentially expressed – that is, among all the rejected null hypotheses.

What we are going to look for in this tutorial is the FDR < 0.05.

Once negative binomial models are fitted and dispersion estimates are obtained for each gene (as explained in the lecture  - “Theory of RNAseq”), it is straight-forward to look for differentially expressed genes. To contrast two conditions, e.g., to see whether there is differential expression between conditions “control” and “treated”, we simply call the function exactTest in edgeR package. 

1. Create a list of differentially expressed genes.

```{r}
# test for differential expression
de <- exactTest(d, pair = c("WR","WL"))
```

For every gene you have performed a test. What distribution of p-values you would expect if you have computed a differential expression of samples in the same biological condition? Do you remember what was false discovery rate (FDR)?

2. Plot a histogram of p-values of all tests. If you do not understand why the the shape of historgram looks like L, ask your assistant.

```{R}
hist(de$table$PValue, breaks = 50, xlab = 'p-value (without correction)')
```

3. Compute FDR all genes, save a sorted table of differentially expressed genes.

```{R}
# gathering differential expressed genes
tT <- topTags(de, n = nrow(d))
# tabular form of differentially expressed genes 
deg.list <- tT$table
head(deg.list)
```

\footnotesize
Function `topTags` calls a method of correction for multiple testing, default is Benjamini-Hochberg method for computing FDR. The top `n` differentially expressed genes are returned. Function returns more details that we need, therefore we extract just `$table` from it.
\normalsize

An MA-plot provides a useful overview for an experiment with a two-group comparison. This plot represents each gene with a dot. The x axis is the average expression over the mean of normalized counts (A-values), the y axis is the log2 fold change between treatments (M-values). Genes with an adjusted p-value below a threshold (e.g. 0.05 or 0.1) are often highlighted. edgeR provides a simple helper function that makes a MA-plot.

2. Create MA plot of the differential expressed genes

```{r}
## take the row names of the differentially expressed genes that have locus ID
locus.ids <- rownames(deg.list)
# select genes that have 1% false discovery rate
top.deg <- locus.ids[deg.list$FDR < .01]
### MA plot
# this produces the MA plot (M - log-fold change, A - log-average expression) 
# with genes that are significantly differentially expressed according to the FDR cutoff 
# (please not that at this point there is NO fold-change cutoff)
# on the plot, signif. diff. expressed genes are colored red 
plotSmear(d, de.tags = top.deg, main = "MA plot on differentiall exprs genes")
```

The “volcano plot” is an effective and easy-to-interpret graph that summarizes both fold-change and a measure of statistical significance from a statistical test (usually a q-value). 
It is a scatter-plot of the negative $log_{10}$-transformed p-values from the gene-specific test (on the y-axis) against the log2 fold change (on the x-axis). This results in data points with low p-values (highly significant) appearing towards the top of the plot. The log2 of the fold-change is used so that changes in both directions (up and down) appear equidistant from the center. 
Plotting points in this way results in two regions of interest in the plot: those points that are found towards the top of the plot that are far to either the left- or the right-hand side. These represent values that display large magnitude fold changes (hence being left- or right- of center) as well as high statistical significance (hence being towards the top). We construct a table containing the $log_{2}$ fold change and the negative $log_{10}$-transformed p-values:

3. Make volcano plot

```{r, echo = F}
## For students - VOLCANO PLOT
plot(deg.list$logFC, -log10(deg.list$PValue), 
     pch=20, main="WL vs WR comparison", xlim=c(-4,4),
     xlab = "Log2 Fold Change", ylab = "-log10(pvalue)")
with(subset(deg.list, FDR<.01 & abs(logFC)>2), 
     points(logFC, -log10(PValue), pch=20, col="lightblue"))
```

We can identify genes (points) in the two regions of interest on the plot: points with large magnitude fold changes (being left- or right- of center) and points with high statistical significance (being towards the top).

***

## 9. RPKM calculations for gene comparisons

A gene clustering heatmap is a two-dimensional, rectangular, coloured grid, representing each data point (rectangle) with a colour that quantitatively and qualitatively reflects the original experimental observations. 
The rows (and/or columns) of the matrix are rearranged (independently) according to some hierarchical clustering method, so that genes or groups of genes with similar expression patterns are adjacent. 
The computed dendrogram (tree) resulting from the clustering is added to a side of the image to indicate the relationships among genes.

In order to test for differential expression, we operate on raw counts and use discrete distributions as described. Since common statistical methods for clustering and ordination, work best for (at least approximately) homoskedastic data; this means that all the observed data (i.e., here, the expression strength of a gene) share the same finite variance (also called homogenity of variance). In RNA-Seq data, however, variance grows with the mean.

1. define a function computing RPKMs given counts per gene and the length of gene we computed at the beginning.

```{r}
## rpkm calculations
rpkm <- function(counts, lengths) {
  rate <- counts / lengths 
  return(rate / sum(counts) * 1e9)
}
```


\footnotesize
This is R syntax for writing functions. Note, that input arguments `counts` and `lengths` are expected as vectors rather than just numbers. Everytime you define your own function it is good starting point to write it for pair of single values and then extend it for vectors as well.
\normalsize

2. Since some genes were filtered on the way here, take a subset of lengths which are still present and make sure, that the genes are in the same order both in `geneLengths` table and `rawcounts` matrix.

```{r}
## merging the rownames so we have ordered things
geneLengths <- geneLength[(geneLength$gene_name) %in% (rownames(rawcounts)),]

## just to check if gene names are in same order in geneLengths table and rawcounts matrix
all(geneLengths$gene_name == rownames(rawcounts))
```


\footnotesize
`==` will compare pairwise members of two vectors returning `True` or `False` for each match or mismatch respectively. Function `all()` returns `True` if all members of input vector are `True` and `False` otherwise.
\normalsize

3. Finally, compute RPKMs.

```{r}
RPKMs <- rpkm(rawcounts, geneLengths$length)
```

4. Make a `data.frame` of RPKMs of top 100 differentially expressed genes. Use log2 transformation.

```{r}
log_rpkm.topgenes <- log2(RPKMs[rownames(deg.list[1:100,]),]+1)
```

\footnotesize
`deg.list` contains sorted list of the most differentially expressed genes. `deg.list[1:100,]` takes a top 100 genes, function `rownames` is returning their names. `RPKMs[<vector_of_names>,]` returns a subset of RPKMs table with rows specified by a vector of names. We add `+1` to be able to do a log transformation, do a `log2` transformation. Note, that in previous section you were working with `matrix`, if you wish to handle `matrix` instead of `data.frame`, you can use function `as.matrix()` to convert a `data.frame`.
\normalsize

5. Create a heatmap of log2 RPKMs of those genes.

```{r}
pheatmap(log_rpkm.topgenes, main = 'Heatmap of top 100 genes')
```

***

\footnotesize
Before you start with following, switch to file `SAGE_RNAseq_2016.Rmd`, everything what you have done you done on gene level. Since the annotation we created is not complete, gene ids are not providing too much information. Therefore, lets do differential expression also of transcripts! Yaaay!
\normalsize

## 10. Your genes (optional)

1. make a list of transcripts / genes you have annotated

```{r}
annotated_transctipts <- paste0('S5_genome_',201:250)
annotated_genes <- tx2genes$gene_id[tx2genes$tx_name %in% annotated_transctipts]
```

\footnotesize
This is just an example, I lets say, that I have annotated genes "S5_genome_201" to "S5_genome_250".
\normalsize

2. Take a subset of deferentially expressed genes from those you have annotated. Are some of them differentially expressed?

```{r}
df_annotated <- annotated_genes[annotated_genes %in% rownames(deg.list[deg.list$FDR < 0.05,])]
length(df_annotated)
```

3. Make a heatmap of those genes.

```{r}
log_rpkm.mygenes <- as.matrix(log2(RPKMs[df_annotated,]+1))
pheatmap(log_rpkm.mygenes, main = 'Heatmap of my annotated genes')
```

***

made by Andrea and Kamil
