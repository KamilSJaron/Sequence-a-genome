---
  output: pdf_document
---

#RNA-seq downstream analysis

Today, we will visualise mapped reads in IGV. Then, we load abundances to R, transform counts to more practical units and perform a differential expression analysis.

## Previously in Sequence a genome...

**unix reminder**
  
- remote connection and file transfer `ssh`, `scp` to server `<username>@prd.vital-it.ch`
- basic commands `pwd`, `ls`, `cd`, `cp`, `mv`, `mkdir` and finally `man` if you forgot anything
- text processing tools `cat`, `head`, `tail`, `less` and `vi`
- operations on cluster `module add`, `bsub` and `bjobs`

**data exploration**
  
- genome, annotation and extraction of coding regions
- quality control of reads using `fastqc`
- trimming of reads

**RNA-seq**

- RNA-seq theory
- building a reference, mapping reads and quantifying read abundances using `kallisto`

***

### Recomended organisation of your local files

Both IGV and R you will run locally, so let me suggest you an organisation of the files, that I will use. If you will use the same, you will have much less work with reusing of the code and also it will simplify problem diagnostics to your assistants.

```
./se2ex3/<your_script>
./genome/<anotation.gtf>
        /<genome.fasta>
./abundances/<conditionreplicate.tsv>
            /...
./scripts/tximport.R
```

\clearpage

## 0. IGV 

1. Start IGV.
2. Create a genome: Genomes $\rightarrow$ Create .genome file.
3. Fill unique descriptor, name and load the `.fasta` and `gtf` files (see following screenshot).

```{r fig.width=6, fig.height=4,echo=FALSE}
library(png)
library(grid)
img <- readPNG("./steps_igv_Genomes_CreateGenomeFile.png")
grid.raster(img)
```

4. Check if you see following screen with loaded genome and annotation

```{r fig.width=6, fig.height=4,echo=FALSE}
img <- readPNG("./IGV_fasta_and_gtf_loaded.png")
grid.raster(img)
```

5. Load your mapped reads: File $\rightarrow$ Load from File... $\rightarrow$ select your `.bam` file.
6. Browse the genome, find your annotated genes. Are they expressed?

***

\clearpage

## 1. Reading annotaiton.

First of all, we need to load information about realtion transcripts to genes and lengths of genes from annotation file.

1. Use `import.gff` function form `rtracklayer` package to load annotation and convert it to `data.frame`

```{r, message=FALSE, warning=FALSE}
library(rtracklayer)

gtf <- import.gff("../genome/Pseudomonas_protegens_S5_genome.gtf")
gtf <- as.data.frame(gtf)
```

\footnotesize
Once, the `.gtf` file is loaded, variable `gtf` carries an non-standard R object. We can convert it to `data.frame`, which we are more fimiliar with.
\normalsize

We are going to need a dictionary of transcripts and gene ids to quantify expression of genes.

2. Create a `data.frame` which will be used as dictionary between transcripts and genes. 

```{r}
genes <- data.frame(tx_name = gtf$transcript_id, 
                    gene_id = gtf$gene_id, 
                    stringsAsFactors = FALSE)

head(genes)
```

3. Check how many times are there genes with multiple transcripts.

```{R}
table(table(genes$gene_id))
```

\footnotesize
\textbf{table of table}: `table` transforms a vector to table of counts from the vector. If you apply function `table` to vector `c('A','A','B','C','C','C','D','D')` it returns a vector `c(2,1,3,2)` with names `c('A','B','C','D')`. If you apply function `table` to the returned vector (the vector `c(2,1,3,2)`), it computes counts of counts - the output will be then `c(1,2,1)` with names `c(1,2,3)`. So we see, that in the original vector there was a one unique letter, two letters twice and one letter three times.
\normalsize

We are also going to need to know lengths of genes to compute RPKM.

4. Compute lengths of all genes as the length of the longest transcript. 

```{r}
gtf <- aggregate(gtf$width, list(gtf$gene_id), max)
```

\footnotesize
\textbf{agregate}: Function `aggregate` can apply a functinon (`max` in our case) to subsets given by a `vector` or a `list`.
\normalsize

***

## 2. Load data

\footnotesize
The starting point for an RNA-Seq experiment is a set of N RNA samples, typically associated with a variety of treatment conditions. Each sample is sequenced, short reads are mapped to the appropriate genome, and the number of reads mapped to each genomic feature of interest is recorded. 

The set of gene-wise counts for sample j makes up the expression profile or library for that sample. The expected size of each count is the product of the library size and the relative abundance of that gene in that sample. As input for data analysis, we expect count data in the form of a matrix of integer values. The matrix in the g-th row and the j-th column of the table tells how many reads have been mapped to gene g in sample j.
\normalsize

1. Download abundancies

The windows users have to use WinSCP, but OS X and Linux users can use command `rsync` for downloading shared directories. The advantage of `rsync` is that it does not simply copy, but rather synchronise. So if you folder already contains some files, they wont be downloaded again. If somebody is feeling unconfortible with this feature, he can use `scp` instead.

```bash
rsync -r <username>@prd.vital-it.ch:/scratch/cluster/monthly/mls_2015/SAGE/abundances .
```

2. Load all needed packagess, save all filenames of abundancies to variable `files` using function `dir`. Check in the manual what the function does.

```{r, message=FALSE, warning=FALSE}
## Load the packages
# source("http://bioconductor.org/biocLite.R")
# biocLite("edgeR")

library(edgeR)
library(readr)
library(ggplot2)
library(pheatmap)
library(reshape2)
library(GenomicFeatures)
path_to_abundances <- '../abundances/'
files <- dir(path_to_abundances, pattern=".tsv$")
files <- paste(path_to_abundances,files, sep = '')
files
```

3. Load function `tximport` from script `tximport.R`. You can download the script from \newline `/scratch/cluster/monthly/mls_2015/SAGE/scripts/tximport.R`. We will use this function to load transcript abundances

```{r, message=FALSE}
source('../scripts/tximport.R')
```

\footnotesize
\textbf{tximport}: is a package which is not released for current version of R. If you will try to install package via bioconductor, you probably fail, if you dont have installed non-yet-released version of R-3.3. However, the package is quite simple, therefore we can whole content of package load to R just using `source()` on the download source code of the package.
\normalsize

4. Import transcript abundancies using function `tximport`. This function automatically recompute transcript abundances to gene abundances using the list you have created earlier. Rename names of columns to condtion and biological replicate...

```{r, message=FALSE}
txi <- tximport(files, type = "kallisto", tx2gene = genes, reader = read_tsv)
names(txi)

# reading names of conditions from filenames
colnames(txi$counts) <- substr(files,nchar(path_to_abundances)+1,
                               nchar(path_to_abundances)+3)
# if you load all 16 files:
# paste(rep(c('LM','SA','WL','WR'), each = 4), rep(1:4,4),sep='') 
```

***

## 3. Data transformation

1. Select data you will work on today.

```{r}
rawcounts <- as.data.frame(txi$counts[,grep("^WL|WR", colnames(txi$counts))])
head(rawcounts)
```

2. Plot a histogram on one sample from raw counts data:

```{r, echo = FALSE}
ggplot(rawcounts, aes(x = WL1)) + geom_histogram(fill = "#525252", binwidth = 2000) + ggtitle("Histogram on Raw Counts for WL 1 sample")
```

3. Transform counts to log scale.

```{r}
pseudoCount <- log2(rawcounts + 1)
```

Do you have an idea, why there is a +1? What would happed if it was not there?

\footnotesize
For data exploration and visualization, it is useful to work with transformed versions of the count data. As the count values distribution is highly skewed, the log2 transformation helps to approximately normalize the distributions.

Log base 2 is typically used as it facilitates the conversion back to the original scale: a difference of 1 on the log base 2 scale corresponds to a fold change of 2 on the original count scale. Since count values for a gene can be zero in some conditions (and non-zero in others), we advocates the use of pseudocounts, i.e. transformations of the form

$Y = log_2(K+1)$; more generally $Y = log_2(K + k_0)$, where $K$ represents the count values and $k_0$ is a positive constant.

Even more, common statistical methods for exploratory analysis of multidimensional data, especially methods for clustering and ordination (e. g., principal-component analysis and the like), work best for (at least approximately) homoskedastic data; this means that the variance of an observable quantity (i.e., here, the expression strength of a gene) does not depend on the mean. 
\normalsize

4. Plot a histogram of tranformed counts.

```{r, echo = FALSE}
ggplot(pseudoCount, aes(x = WL1)) + ylab(expression(log[2](count + 1))) +
  geom_histogram(colour = "white", fill = "#525252", binwidth = 0.6) + ggtitle("Histogram on PseudoCounts for LM 1 sample")
```

***

## 4. Raw data filtering

Data quality assessment (QA) and exploration are essential steps of any data analysis. These steps should typically be performed very early in the analysis of a new data set, preceding or in parallel to the normalization step and differential expression testing. 
Our purpose is the detection of differentially expressed genes, not of experimental errors. In particular, we want to identify and possibly remove samples whose experimental treatment suffered from an abnormality that renders the data points obtained from these particular samples detrimental to our purpose. 

The QA processes run on the raw data might reveal technical issues, but other biases might still be present in your data and the best (only?) way to control for those is visual. For example, one could compare replicates (in which case, biological replicates are best), by: 

-	looking differences in count distribution between samples, 
-	plotting a scatterplot of replicates, 
-	sample clustering

In RNA-Seq data, however, variance grows with the mean, with larger variances for larger counts. For example, if one performs PCA directly on a matrix of “normalized” read counts, the result typically depends only on the few most strongly expressed genes because they show the largest absolute differences between samples. A simple strategy to avoid this is to take the logarithm of the “normalized” count values plus a small constant; however, now the genes with low counts tend to dominate the results because, due to the strong “Poisson” noise inherent to small count values, they show the strongest relative differences between samples.

In order to make counts approximately homoskedastic, the packages edgeR offers function to transform the data:

\textcolor{red}{WARNING:} Note that these transformations are provided for applications other than differential testing. For differential testing to operate on raw counts and to use discrete distributions.

1. Calculate counts per milion

```{r}
cpms <- cpm(rawcounts)
```

2. Trash weakly expressed genes - keep the features above the 1 count per milion in at least one groups

```{r}
keep <- rowSums(cpms > 1) >= 4
countsFilter <- rawcounts[keep,]

dim(rawcounts)
dim(countsFilter)
```


```{r, message=FALSE, warning=FALSE}
pseudocountsFilter <- log2(countsFilter+1)
```

3. Plot histogram of pseudocounts

```{r, echo = FALSE}
dfFilter <- melt(pseudocountsFilter)
dfFilter <- data.frame(dfFilter, Condition = substr(dfFilter$variable, 1, 2))
ggplot(dfFilter, aes(x = value, colour = variable, fill = variable)) +
  geom_histogram(binwidth = 0.6) + facet_wrap(~ Condition) +
  theme(legend.position = "top") + xlab("pseudocounts") + ggtitle("Filtered Pseudocounts distribution")
```

***

## 5. Data exploration and quality assessment

The boxplot provides an easy way to visualize the distribution of pseoudocounts in each sample. In the boxplot display, a box is formed with sides at the 25-th and 75-th quantiles of the distribution. A line within the box represent median. Whiskers, those lines out of the box, extend out from the box to minimal and maximal value respectively, but at most in the distance of the 1.5x interquartile range. Data points outside of this range are usually called outliers and plotted as individual points.

1. Make boxplots per samples using `boxplot`, `legend` or `ggplot`.

```{r, echo=FALSE}
df.samples <- melt(countsFilter)
df.samples  <- data.frame(df.samples, Condition = substr(df.samples$variable, 1, 2))

ggplot(df.samples, aes(x = variable, y = value, fill = Condition)) + 
  geom_boxplot(outlier.shape = NA) + xlab("") +
  ylab(expression(log[2](count + 1))) + scale_fill_manual(values = c("#619CFF", "#F564E3")) +
  ylim(0,400) + ggtitle("Samples boxplot")
```

***
\clearpage

## 6. Clustering of the sample-to-sample distances

To explore the similarities and dissimilarities between samples, it is often instructive to look a clustering heatmap of sample-to-sample distance matrix. 
A heatmap is a two-dimensional, rectangular, coloured grid. It displays data that themselves come in the form of a square matrix:

- the colour of each rectangle is determined by the value of the corresponding entry in the matrix, 
-	the rows and columns of the matrix are rearranged independently according to some hierarchical clustering method (Euclidean distance is the most used one), so that similar rows and columns are placed next to each other, respectively

1. Plot a heatmap of Spearman correlations

```{r}
heatmap.plotting.replicates <- function(x, name){
  library(reshape2)
	library(ggplot2)
	spearman.tissue <- melt(cor(x, method = "spearman"))
	colnames(spearman.tissue)[3] <- "spear.corr"

	qp <- qplot(x=Var1, y=Var2, 
	            data=spearman.tissue, fill=spear.corr, 
	            geom="tile", xlab = "", ylab = "") + 
	  theme(panel.grid.major = element_blank(), 
	        panel.grid.minor = element_blank(), 
	        panel.background = element_blank(), 
	        axis.text.x = element_text(angle = 45, hjust = 1)) + 
	  labs(title = name)

	return(qp)
}

heatmap.plotting.replicates(pseudocountsFilter, "Heatmap WR-WL samples")
```

***

## 7. MDS of samples
The purpose of multidimensional scaling (MDS) is to provide a visual representation of the pattern of proximities (i.e., similarities or distances) among a set of objects. MDS takes a set of similarities and returns a set of points such that the distances between the points are approximately equal to the similarities. The similarities between each pair of samples (columns) is the root-mean-square deviation (Euclidean distance) for the top genes. Distances on the plot can be interpreted as leading log2-fold-change, meaning the typical (root-mean-square) log2-fold-change between the samples for the genes that distinguish those samples. The function plotMDS has an argument gene.selection which, set to "common", chooses as top genes those with the largest root-mean-square deviations between samples.

The plotMDS is a simple helper function from edgeR that performs the MDS and makes the plot

1. Build a MDS plot of samples

```{r}
conditions <- c(rep("WL",3), rep("WR",3))
d <- DGEList(counts = countsFilter, group = conditions)
d <- calcNormFactors(d) # TMM is default - Estimate normalization factors
# inspect the relationships between your samples by mds plot
plotMDS(d, labels = colnames(cpms), 
        col = c("darkgreen","blue")[factor(conditions)], 
        main = "MDS plot on samples")
```

## 8. Your genes

**Challenge**

1. make a list of genes you ve anotated
2. list of expressions of those genes
3. compare visually those expression under different conditions

***

content by Andrea; typesetting by Kamil
